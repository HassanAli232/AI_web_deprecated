<!DOCTYPE html>

<html lang="ar">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ML in Arabic</title>
  </head>

  <body>
    <h1>تعلم الآلة</h1>
    <p>
      Lorem ipsum dolor sit amet consectetur adipisicing elit. Sit doloremque
      similique totam quia enim illum harum dignissimos. Tenetur iusto
      reprehenderit dignissimos! Numquam sequi eligendi vel excepturi corrupti,
      voluptate unde expedita facilis sint quod iure quia sit asperiores et
      similique nulla.
    </p>

    <!-- Table of the most important Algos. in ML -->
    <h2>أشهر الخوارزميات</h2>
    <table border="1">
      <!-- Table head -->
      <thead>
        <tr>
          <th>Algo. Name</th>

          <th>history</th>

          <th>description</th>
        </tr>
      </thead>

      <!-- Llinear regression -->
      <tr>
        <td>Linear regression</td>
        <td>1796</td>
        <td>
          Linear regression models the relationship between a dependent variable
          and one or more independent variables by fitting a linear equation.
          It's used for predicting a continuous outcome.
        </td>
      </tr>

      <!-- Logistic Regression (1844) -->
      <tr>
        <td>Logistic Regression</td>
        <td>1844</td>
        <td>
          Logistic regression is used for binary classification tasks. It models
          the probability that a given input belongs to one of two classes using
          the logistic function.
        </td>
      </tr>

      <!-- Decision Trees (1960s) -->
      <tr>
        <td>Decision Trees</td>
        <td>1960</td>
        <td>
          Decision trees recursively partition data into subsets based on the
          values of input features, leading to a tree-like structure. They are
          used for both classification and regression tasks.
        </td>
      </tr>

      <!-- K-Nearest Neighbors (K-NN) (1967) -->
      <tr>
        <td>K-Nearest Neighbors (K-NN)</td>
        <td>1967</td>
        <td>
          K-NN is a simple instance-based learning algorithm. It classifies data
          points by the majority class of their k-nearest neighbors in feature
          space.
        </td>
      </tr>

      <!-- Support Vector Machines (SVM) 1964 -->
      <tr>
        <td>Support Vector Machines (SVM)</td>
        <td>1964</td>
        <td>
          SVM is a powerful algorithm for binary classification. It finds the
          optimal hyperplane that best separates two classes in high-dimensional
          space.
        </td>
      </tr>
    </table>

    <a href="/index.html">الصفحة الرئيسية</a>
  </body>
</html>
